# Goorm Practice04

# 수행과제

## IaC를 통한 불변 인프라(Immutable infrastructure) 구현

-   Terraform/Ansible 중 하나의 IaC 도구를 선택하여 제시된 AWS 위 설계된 아키텍쳐를 배포합니다. 환경에 해당하는 VPC/Subnet 등과 자원에 해당하는 EC2/RDS 등을 구분하여 배포할 수 있도록 작성해야 합니다. 아키텍쳐에서 제시한 이름과 동일한 이름으로 배포될 수 있도록 설계합니다.

[이미지]

## CI/CD 파이프라인 구축을 통한 자동화된 이미지 배포

-   과제 설명 강의에서 배운 Jenkins를 활용하여 과제 1번에서 직접 배초한 Public Web EC2에 Tomcat 서버를 배포합니다.(배포될 Tomcat server는 Web server에 해당하지 않지만, 평가의 용이를 위해 web server에 배포함을 알립니다.) Jenkins를 동작시키기 위한 환경은 별도로 원하는 대로 구성합니다. Tomcat server는 강의 내용을 참고하도록 합니다.

# 아키텍처 해석

제공된 다이어그램을 하나씩 해석해보자.

## VPC

> -   ap-northeast-2에 goorm 이라는 명칭을 가지는 VPC를 생성한다.
> -   goorm VPC는 AZ를 ap-northeast-2a와 ap-northeast-2c를 사용한다.
> -   각 AZ에 public subnet 1개, private subnet 2개를 가진다.
> -   Route Table은 public 1개와 private 2개, 총 3개를 가진다.
> -   VPC에 접근하는 Internal Gateway가 존재한다.
> -   NAT Gateway는 단일로 존재하며, ap-northeast-2a의 public에 위치한다.

## Web

> -   IGW와 연결되는 Web ALB가 존재한다.
> -   Web ALB는 Web Auto Scaling group에 트래픽을 분산한다.
> -   ap-northeast-2a와 ap-northeast-2c 두 가용영역에 걸친 Web Auto Scaling group이 존재한다.

## App

> -   private와 연결되는 NLB가 존재한다.
> -   App lb는 App Auto Scaling group에 트래픽을 분산한다.
> -   ap-northeast-2a와 ap-northeast-2c 두 가용영역에 걸친 App Auto Scaling group을 존재한다.

## DB

> -   ap-northeast-2a에 RDB가 위치한다.
> -   App Auto Scaling group에서 RDB에 접근 가능하다.
> -   RDB의 read replica가 ap-northeast-2c AZ에 위치한다.

아키텍처를 분석한 사항에 맞춰 컴포넌트를 제작한다.

# 프로비저닝

AWS의 리소스를 만들기위한 IaC로는 `Terraform`이 목적에 부합한다. 따라서 `Terraform`을 활용하여 본 아키텍처를 코드화 시킨다.

## VPC

### VPC

-   `cidr_block `은 Aws Consol에서 생성할때 제공되는 기본값과 맞추었다.
-   `instance_tenancy`: 특별히 지정된 사항은 없어 기본값인 `default`를 사용한다.

```
resource "aws_vpc" "goorm-vpc" {
  cidr_block       = "10.0.0.0/16"
  instance_tenancy = "default"

  tags = {
    Name = "GoormVpc"
  }
}
```

### Subnet

서브넷의 목적은 네트워크의 분할이다. 따라서 public, private 서브넷은 서브넷 생성에서는 구분되지 않는다. 이후 네트워크와 연결되는 방법에서 차이가 존재하는 것을 알 수 있다.

-   `vpc_id` : 위치할 vpc를 설정해주어야 한다.
-   `cidr_block `: vpc와 마찬가지로 aws console에서 6개 서브넷 생성할때 기준으로 기본값으로 지정하였다. 실제 서브넷에 위치하는 pc 대수가 16대보다 많을 것 같지는 않아 `10.0.0.0/20` `10.0.0.0/24` 모두 상관없을 것이다.
-   `availability_zone`: 서브넷이 위치할 가용영역을 지정해준다.

```HCL
# 공개 서브넷 a :web
resource "aws_subnet" "web-public-subnet-a" {
  vpc_id            = aws_vpc.goorm-vpc.id
  cidr_block        = "10.0.0.0/20"
  availability_zone = "ap-northeast-2a"

  tags = {
    Name = "WebPublicSubnetA"
  }
}
```

### Internal Gateway (IGW)

위치할 vpc에 대한 정보만 지정하면 특별히 다른 설정은 필요하지 않다.

`vpc_id`: 위치할 vpc에 대한 정보이다.

```hcl
resource "aws_internet_gateway" "goorm-igw" {
  vpc_id = aws_vpc.goorm-vpc.id

  tags = {
    Name = "GoormIGW"
  }
}
```

### NAT Gateway (NAT GW)

nat 생성시 주의해야하는 점은 eip가 없으면 문제가 발생한다는 것이였다.

-   `domain`: 해당 eip가 VPC에 할당되는지에 대한 정보를 표시한다.

```hcl
# NAT
resource "aws_eip" "goorm-nat-eip" {
	domain = "vpc"
}
```

-   `allocation_id`: nat가 사용할 탄력 ip에 대한 id이다.
-   `subnet_id`: nat가 위치할 서브넷을 지정한다.

```hcl
resource "aws_nat_gateway" "goorm-nat-gateway" {
  allocation_id = aws_eip.goorm-nat-eip.id
  subnet_id     = aws_subnet.web-public-subnet-a.id

  tags = {
    Name = "GoormNatGateway"
  }
}
```

### Route Table

라우트 테이블 생성또한 주의해야 하는 점이 몇 가지 있다.

1. 라우트 테이블을 생성하고, 서브넷과 직접 연결을 해주어야한다.
2. 라우트 테이블과 서브넷의 속성의 맞춰서 게이트웨이를 지정해야한다.

해당 사항에 주의하며 테이블을 생성한다.

-   `vpc_id`: 라우트 테이블이 위치할 vpc 정보이다.
-   `route.cidr_block`: 특별히 제한을 두지 않는 모든 ip를 허용한다.
-   `route.gateway_id `: Public Subnet과 연결되는 테이블이므로 IGW와 연결하여 외부와 자유로운 통신을 설정한다.
-   `route.nat_gateway_id `: Private Subnet과 연결되는 라우트 테이블에는 NAT GW와 연결해야 한다. 적절한 파라미터를 사용하여 서브넷의 속성을 구분한다.

```hcl
# Web Route Table 설정
resource "aws_route_table" "web-route-table" {
  vpc_id = aws_vpc.goorm-vpc.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.goorm-igw.id
  }

  tags = {
    Name = "WebRouteTable"
  }
}
```

-   `subnet_id`: 라우트 테이블과 연결될 서브넷을 지정한다.
-   `route_table_id`: 서브넷과 연결될 라우트 테이블을 지정한다.

```hcl
resource "aws_route_table_association" "web-route-table-association-a" {
  subnet_id      = aws_subnet.web-public-subnet-a.id
  route_table_id = aws_route_table.web-route-table.id
}

resource "aws_route_table_association" "web-route-table-association-c" {
  subnet_id      = aws_subnet.web-public-subnet-c.id
  route_table_id = aws_route_table.web-route-table.id
}
```

## Security Group

VPC 내부 리소스들에 대한 보안 정책을 통합하여 관리할 보안 그룹을 생성하는 것이 유리하다 판단하였다. 따라서 다른 리소스를 생성하기 전 보안그룹을 먼저 작성하였다.

-   `vpc_id`: 보안 그룹이 사용될 vpc 정보이다.
-   `ingress`: 인바운드 규칙을 생성한다. 기본적인 ssh, http, https와 app 배포를 위한 8080, MySql을 위한 3306을 열어 두었다. web, app, db 모두 따로 관리를 하는게 적절하지만 편의를 위하여 통합하여 작성했다.
-   `egress`: 아웃바운드 규칙을 생성한다. 나가는 트래픽에 대한 제한은 두지 않는다.
-   `egress.protocol`: -1로 설정할 경우 모든 프로토콜에 대하여 허용한다는 의미가 된다.

```
# 보안 그룹 생성
resource "aws_security_group" "goorm-sg" {
  name        = "goorm-sg"
  vpc_id      = aws_vpc.goorm-vpc.id

  # 인바운드 규칙
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 8080
    to_port     = 8080
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 3306
    to_port     = 3306
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # 아웃바운드 규칙
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "GoormSG"
  }
}
```

## Load Balancer

```hcl
# App NLB
resource "aws_lb" "app-lb" {
  name               = "app-lb"
  load_balancer_type = "network"
  security_groups    = [aws_security_group.goorm-sg.id]
  subnets            = [aws_subnet.app-private-subnet-a.id, aws_subnet.app-private-subnet-c.id]
}

# App NLB Target Group
resource "aws_lb_target_group" "app-tg" {
  name     = "app-target-group"
  protocol = "TCP"
  port = 8080
  vpc_id   = aws_vpc.goorm-vpc.id
}

# App NLB Listener
resource "aws_lb_listener" "app-lb-listener" {
  load_balancer_arn = aws_lb.app-lb.arn
  protocol          = "TCP"
  port              = 8080

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app-tg.arn
  }
}
```
